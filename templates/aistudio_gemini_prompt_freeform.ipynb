{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwyTRdwB8aW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RXInneX6xx7c"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.8.2\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "OOpqw5rJbDD5",
        "outputId": "1eb71946-4739-43f7-a7a5-3c6a633aa32d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.jpg  \u001b[0m\u001b[01;34msample_data\u001b[0m/  \u001b[01;34mtempfiles\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "def upload_to_gemini(path, mime_type=None):\n",
        "  \"\"\"Uploads the given file to Gemini.\n",
        "\n",
        "  See https://ai.google.dev/gemini-api/docs/prompting_with_media\n",
        "  \"\"\"\n",
        "  file = genai.upload_file(path, mime_type=mime_type)\n",
        "  print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
        "  return file\n",
        "\n",
        "# Create the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 40,\n",
        "  \"max_output_tokens\": 8192,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-1.5-pro\",\n",
        "  generation_config=generation_config,\n",
        ")\n",
        "\n",
        "# TODO Make these files available on the local file system\n",
        "# You may need to update the file paths\n",
        "files = [\n",
        "  upload_to_gemini(\"2.jpg\", mime_type=\"image/jpeg\"),\n",
        "  upload_to_gemini(\"1.jpg\", mime_type=\"image/jpeg\"),\n",
        "]\n",
        "\n",
        "chat_session = model.start_chat(\n",
        "  history=[{\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [\n",
        "        files[0],\n",
        "        \"ËØ•ÂõæÊòØ‰∏Ä‰∏™ÈúÄË¶ÅËøõË°åÂå∫Âüü‰æõÁÉ≠Á≥ªÁªüËßÑÂàíËÆæËÆ°ÁöÑÂØπË±°ÔºåÁé∞ÊúâÁÉ≠Ê∫êÂíåÂÖ≠‰∏™Ë¥üËç∑ÔºåÈúÄË¶Å‰Ω†ËøõË°åË¥üË¥£ËÆæËÆ°‰∏Ä‰∏™‰æõÁÉ≠Á≥ªÁªüÊãìÊâëÁªìÊûÑ„ÄÇÊâÄÊûÑÂª∫ÁöÑÊãìÊâëÁªìÊûÑÈúÄË¶Å‰∏•Ê†ºÈÅµÂæ™‰ª•‰∏ãÔºö‰Ω†ÈúÄË¶ÅÂØπÂêÑ‰∏™ÂØπË±°ÂíåÁÆ°ÈÅì‰∫§Êé•Â§ÑËÆæÁΩÆËäÇÁÇπÔºåËäÇÁÇπËøûÊé•‰ª£Ë°®ÁÆ°ÈÅìÔºåËøô‰∫õÁÆ°ÈÅì‰∏çËÉΩÁ©øËøáÂª∫Á≠ëÂè™Âú®Âõæ‰∏≠ÁöÑÈÅìË∑ØËøõË°åËÆæËÆ°„ÄÇ\\nÂ¶ÇÊûúÂêåÂêëÊúâÂ§ö‰∏™Ë¥üËç∑ÔºåÈÇ£‰πàËØ•‰∏ªÁÆ°ÈÅìÈúÄË¶ÅËøõË°åÂàÜÊîØÔºåÂπ∂‰∏îÂàÜÊîØÂêéÁöÑÊñ∞ËäÇÁÇπËøûÊé•Ëá≥Ëøô‰∏§‰∏™Ë¥üËç∑„ÄÇ\\nÂêå‰∏Ä‰∏™ËäÇÁÇπ‰∏çËÉΩËøûÊé•Ë∂ÖËøá3‰∏™ÁÆ°ÈÅìÔºåÂ¶ÇÊûúÊúâÈúÄË¶ÅËÆæËÆ°ÁÆ°ÈÅìÂàÜÊîØ„ÄÇ\\n\\nÂèÇËÄÉÔºöÁÉ≠Ê∫êËäÇÁÇπÁºñÂè∑‰∏∫1ÔºõÊÄªÈÉ®Âü∫Âú∞ËäÇÁÇπÁºñÂè∑‰∏∫2ÔºõÂïÜÂä°‰∏≠ÂøÉËäÇÁÇπÁºñÂè∑‰∏∫3ÔºõÁªøÂàõÂ§ßÂé¶ËäÇÁÇπÁºñÂè∑‰∏∫4ÔºõÂåóÈÉ°ËäÇÁÇπÁºñÂè∑‰∏∫5ÔºõÂÖâÊòéÂ∫úËäÇÁÇπÁºñÂè∑‰∏∫6ÔºõÂ£πÂè∑Â§©Á¶ßËäÇÁÇπÁºñÂè∑‰∏∫7„ÄÇ‰Ω†ËøòÈúÄË¶ÅÂØπÂÖ∂‰ªñËäÇÁÇπÈ¢ùÂ§ñÂÆö‰πâÁºñÂè∑„ÄÇ\\n\\nËØ∑‰Ω†Áî®ËøîÂõû‰∏Ä‰∏™ÂàóË°®ÔºåÂÖ∂‰∏≠ÂàóË°®ÂÖÉÁ¥†ÂåÖÂê´Ôºànode_id1,node_id2Ôºâ‰ª£Ë°®‰ªéËäÇÁÇπÁºñÂè∑node_id1ÊµÅÂÖ•ËäÇÁÇπÁºñÂè∑node_id2„ÄÇ\\nÁªìÊûúÊ®°Áâà‰æãÂ¶ÇÔºö‚Äú[\\n(1, 5), # ÁÉ≠Ê∫ê -> ËäÇÁÇπ5\\n(5, 6), # ËäÇÁÇπ5 -> ËäÇÁÇπ6\\n(6, 2), # ËäÇÁÇπ6 -> ÊÄªÈÉ®Âü∫Âú∞\\n(6, 4), # ËäÇÁÇπ6 -> Â£πÂè∑Â§©Á¶ß\\n(5, 3) # ËäÇÁÇπ5 -> ÂïÜÂä°‰∏≠ÂøÉ\\n]‚Äù\",\n",
        "      ],\n",
        "    },\n",
        "  {\n",
        "      \"role\": \"model\",\n",
        "      \"parts\": [\n",
        "        \"```\\n[\\n(1, 8),  # ÁÉ≠Ê∫ê -> ËäÇÁÇπ8\\n(8, 9),  # ËäÇÁÇπ8 -> ËäÇÁÇπ9\\n(9, 2),  # ËäÇÁÇπ9 -> ÊÄªÈÉ®Âü∫Âú∞\\n(9, 7),  # ËäÇÁÇπ9 -> Â£πÂè∑Â§©Á¶ß\\n(8, 10), # ËäÇÁÇπ8 -> ËäÇÁÇπ10\\n(10, 11),# ËäÇÁÇπ10 -> ËäÇÁÇπ11\\n(11, 5), # ËäÇÁÇπ11 -> ÂåóÈÉ°\\n(11, 6), # ËäÇÁÇπ11 -> ÂÖâÊòéÂ∫ú\\n(10, 3)  # ËäÇÁÇπ10 -> ÂïÜÂä°‰∏≠ÂøÉ\\n]\\n```\",\n",
        "      ],\n",
        "    },\n",
        "  ]\n",
        ")\n",
        "\n",
        "response = chat_session.send_message(\"INSERT_INPUT_HERE\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "j04BDYw0a1hF",
        "outputId": "d81bd7db-be91-448c-fe99-8a62b3b43d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded file '2.jpg' as: https://generativelanguage.googleapis.com/v1beta/files/zaj55mn7tybp\n",
            "```\n",
            "[\n",
            "(1, 8), # ÁÉ≠Ê∫ê -> ËäÇÁÇπ8\n",
            "(8, 9), # ËäÇÁÇπ8 -> ËäÇÁÇπ9\n",
            "(9, 2), # ËäÇÁÇπ9 -> ÊÄªÈÉ®Âü∫Âú∞\n",
            "(9, 7),  # ËäÇÁÇπ9 -> Â£πÂè∑Â§©Á¶ß\n",
            "(8, 10), # ËäÇÁÇπ8 -> ËäÇÁÇπ10\n",
            "(10, 11), # ËäÇÁÇπ10 -> ËäÇÁÇπ11\n",
            "(11, 4), # ËäÇÁÇπ11 -> ÁªøÂàõÂ§ßÂé¶\n",
            "(11, 12), # ËäÇÁÇπ11 -> ËäÇÁÇπ12\n",
            "(12, 3), # ËäÇÁÇπ12 -> ÂïÜÂä°‰∏≠ÂøÉ\n",
            "(10, 13), # ËäÇÁÇπ10 -> ËäÇÁÇπ13\n",
            "(13, 5), # ËäÇÁÇπ13 -> ÂåóÈÉ°\n",
            "(13, 6) # ËäÇÁÇπ13 -> ÂÖâÊòéÂ∫ú\n",
            "]\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [\n",
        "        files[1],\n",
        "        prompt],\n",
        "    },{\n",
        "      \"role\": \"model\",\n",
        "      \"parts\": [\"\"\"[\n",
        "(1, 4), # ÁÉ≠Ê∫ê -> ËäÇÁÇπ4\n",
        "(4, 2), # ËäÇÁÇπ4 -> load1\n",
        "(4, 3) # ËäÇÁÇπ4 -> load2\n",
        "]\"\"\"],\n",
        "    },"
      ],
      "metadata": {
        "id": "DHqL-5lmiaF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"\"\"ËØ•ÂõæÊòØ‰∏Ä‰∏™ÈúÄË¶ÅËøõË°åÂå∫Âüü‰æõÁÉ≠Á≥ªÁªüËßÑÂàíËÆæËÆ°ÁöÑÂØπË±°ÔºåÁé∞ÊúâÁÉ≠Ê∫êÂíåÂÖ≠‰∏™Ë¥üËç∑ÔºåÈúÄË¶Å‰Ω†ËøõË°åË¥üË¥£ËÆæËÆ°‰∏Ä‰∏™‰æõÁÉ≠Á≥ªÁªüÊãìÊâëÁªìÊûÑ„ÄÇ\n",
        "ÊâÄÊûÑÂª∫ÁöÑÊãìÊâëÁªìÊûÑÈúÄË¶Å‰∏•Ê†ºÈÅµÂæ™‰ª•‰∏ãËßÑÂàôÔºö\n",
        "1.‰Ω†ÈúÄË¶ÅÂ∞ÜÁÉ≠Ê∫êÂíåÂêÑ‰∏™Ë¥üËç∑ÈÄöËøáËäÇÁÇπËøõË°åËøûÊé•„ÄÇËäÇÁÇπËøûÊé•‰ª£Ë°®ÁÆ°ÈÅìÔºå‰ΩÜÊòØÔºåËøô‰∫õÁÆ°ÈÅì‰∏çËÉΩÁ©øËøáÂª∫Á≠ëÂè™Âú®Âõæ‰∏≠ÁöÑÈÅìË∑ØËøõË°åËÆæËÆ°Ôºå‰Ω†ÈúÄË¶Å‰∏çÊñ≠ÂèçÊÄùËÆæËÆ°ÁöÑÁªìÊûÑÊòØÂê¶‰ºöÁ©øËøáÂõæ‰∏≠ÁöÑÂª∫Á≠ëÊàñËÄÖÊπñ„ÄÇ\n",
        "2.‰Ω†ÂøÖÈ°ªÂÖàÁêÜËß£Âõæ‰∏≠ÂêÑ‰∏™Ë¥üËç∑‰πãÈó¥‰ª•ÂèäÁÉ≠Ê∫êÁöÑÁõ∏ÂØπ‰ΩçÁΩÆÂÖ≥Á≥ª„ÄÇÂ¶ÇÊûúËØ•ËäÇÁÇπÂêåÂêëÊúâ‰∏§‰∏™Ë¥üËç∑ÔºåÈÇ£‰πàÈúÄË¶ÅÊñ∞Â¢ûÊîØË∑ØÂàÜÊîØËäÇÁÇπÔºåÂÜçÂàÜÂà´ËøûÊé•Ëá≥Ëøô‰∏§‰∏™Ë¥üËç∑„ÄÇ\n",
        "3.ÊØè‰∏™Êñ∞Â¢ûÁöÑÊîØË∑ØËäÇÁÇπÔºàÈô§‰∫ÜË¥üËç∑ËäÇÁÇπÂíåÁÉ≠Ê∫êËäÇÁÇπÔºâÂøÖÈ°ªËøûÊé•ÂÖ∂‰ªñ3‰∏™ËäÇÁÇπÔºåÂ¶ÇÊûúÊúâÈúÄË¶ÅËÆæËÆ°ÁÆ°ÈÅìÂàÜÊîØ„ÄÇ\n",
        "4.ÁÉ≠Ê∫êËäÇÁÇπÂè™ËÉΩ‰Ωú‰∏∫Ê∫êËäÇÁÇπÔºåË¥üËç∑ËäÇÁÇπÂè™ËÉΩ‰Ωú‰∏∫ÁõÆÊ†áËäÇÁÇπ„ÄÇ\n",
        "\n",
        "ÂèÇËÄÉÔºöÁÉ≠Ê∫êËäÇÁÇπÁºñÂè∑‰∏∫1ÔºõÊÄªÈÉ®Âü∫Âú∞ËäÇÁÇπÁºñÂè∑‰∏∫2ÔºõÂïÜÂä°‰∏≠ÂøÉËäÇÁÇπÁºñÂè∑‰∏∫3ÔºõÁªøÂàõÂ§ßÂé¶ËäÇÁÇπÁºñÂè∑‰∏∫4ÔºõÂåóÈÉ°ËäÇÁÇπÁºñÂè∑‰∏∫5ÔºõÂÖâÊòéÂ∫úËäÇÁÇπÁºñÂè∑‰∏∫6ÔºõÂ£πÂè∑Â§©Á¶ßËäÇÁÇπÁºñÂè∑‰∏∫7„ÄÇ‰Ω†ËøòÈúÄË¶ÅÂØπÂÖ∂‰ªñÊñ∞Â¢ûÁöÑÊîØË∑ØËäÇÁÇπÁºñÂè∑È¢ùÂ§ñËøõË°åÂÆö‰πâ„ÄÇ\n",
        "\n",
        "ËØ∑‰Ω†Áî®ËøîÂõû‰∏Ä‰∏™ÂàóË°®ÔºåÂÖ∂‰∏≠ÂàóË°®ÂÖÉÁ¥†ÂåÖÂê´ÔºàÊ∫êËäÇÁÇπnode_id1,ÁõÆÊ†áËäÇÁÇπnode_id2ÔºâÔºå‰ª£Ë°®‰ªéÊ∫êËäÇÁÇπÁºñÂè∑node_id1ÊµÅÂÖ•ÁõÆÊ†áËäÇÁÇπÁºñÂè∑node_id2„ÄÇ\n",
        "ÁªìÊûúÊ®°Áâà‰æãÂ¶ÇÔºö‚Äú[\n",
        "(1, 5), # ÁÉ≠Ê∫ê -> ËäÇÁÇπ5\n",
        "(5, 6), # ËäÇÁÇπ5 -> ËäÇÁÇπ6\n",
        "(6, 2), # ËäÇÁÇπ6 -> ÊÄªÈÉ®Âü∫Âú∞\n",
        "(6, 4), # ËäÇÁÇπ6 -> Â£πÂè∑Â§©Á¶ß\n",
        "(5, 3) # ËäÇÁÇπ5 -> ÂïÜÂä°‰∏≠ÂøÉ\n",
        "]‚Äù\"\"\""
      ],
      "metadata": {
        "id": "w5cNlI9Be50L"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_ = [\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [\n",
        "        files[1],\n",
        "        prompt],\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"model\",\n",
        "      \"parts\": [\"\"\"[\n",
        "(1, 4), # ÁÉ≠Ê∫ê -> ËäÇÁÇπ4\n",
        "(4, 2), # ËäÇÁÇπ4 -> load1\n",
        "(4, 3) # ËäÇÁÇπ4 -> load2\n",
        "]\"\"\"],\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [\n",
        "        files[0],\n",
        "        prompt],\n",
        "    },\n",
        "  ]\n",
        "for i in range(5):\n",
        "  chat_session = model.start_chat(\n",
        "  history=history_\n",
        "  )\n",
        "  response = chat_session.send_message(\"INSERT_INPUT_HERE\")\n",
        "  print(response.text)\n",
        "  model_results = {\n",
        "      \"role\": \"model\",\n",
        "      \"parts\": [response.text],\n",
        "    }\n",
        "  history_.append(model_results)\n",
        "\n",
        "  model_start = {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": [\n",
        "        \"ËØ∑‰Ω†ÊÄùËÄÉËøô‰∏™ÁªìÊûúÊòØÂê¶ÂêàÁêÜÔºåÊòØÂê¶ÈÅµÂæ™ËßÑÂàôÔºåÂ¶ÇÊûúÈÅµÂÆàÂàôËæìÂá∫mark=1ÔºåÂ¶ÇÊûú‰∏çÈÅµÂÆàÊ†πÊçÆËßÑÂàôÊîπËøõÔºåÈáçÊñ∞ËÆæËÆ°ÊãìÊâëÁªìÊûÑ„ÄÇ\"\n",
        "        ],\n",
        "    }\n",
        "  history_.append(model_start)"
      ],
      "metadata": {
        "id": "fBMrPUfjdfoL",
        "outputId": "3a31ddb0-695e-40ee-857a-6f04484e777f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```python\n",
            "[\n",
            "(1, 8),  # ÁÉ≠Ê∫ê -> ËäÇÁÇπ8\n",
            "(8, 2),  # ËäÇÁÇπ8 -> ÊÄªÈÉ®Âü∫Âú∞\n",
            "(8, 9),  # ËäÇÁÇπ8 -> ËäÇÁÇπ9\n",
            "(9, 3),  # ËäÇÁÇπ9 -> ÂïÜÂä°‰∏≠ÂøÉ\n",
            "(9, 7),  # ËäÇÁÇπ9 -> Â£πÂè∑Â§©Á¶ß\n",
            "(9, 10), # ËäÇÁÇπ9 -> ËäÇÁÇπ10\n",
            "(10, 6), # ËäÇÁÇπ10 -> ÂÖâÊòéÂ∫ú\n",
            "(10, 5), # ËäÇÁÇπ10 -> ÂåóÈÉ°\n",
            "(10, 4)  # ËäÇÁÇπ10 -> ÁªøÂàõÂ§ßÂé¶\n",
            "]\n",
            "```\n",
            "\n",
            "‰Ω†ÁöÑÊãìÊâëÁªìÊûÑ‰∏çÂÆåÂÖ®Á¨¶ÂêàËßÑÂàô3ÔºöÊØè‰∏™Êñ∞Â¢ûÁöÑÊîØË∑ØËäÇÁÇπÔºàÈô§‰∫ÜË¥üËç∑ËäÇÁÇπÂíåÁÉ≠Ê∫êËäÇÁÇπÔºâÂøÖÈ°ªËøûÊé•ÂÖ∂‰ªñ3‰∏™ËäÇÁÇπ„ÄÇ\n",
            "\n",
            "‰Ω†ÁöÑÊñπÊ°à‰∏≠Ôºö\n",
            "* ËäÇÁÇπ8ËøûÊé•‰∫Ü3‰∏™ËäÇÁÇπÔºàÁÉ≠Ê∫êÔºåÊÄªÈÉ®Âü∫Âú∞ÔºåËäÇÁÇπ9Ôºâ - Á¨¶ÂêàËßÑÂàô\n",
            "* ËäÇÁÇπ9ËøûÊé•‰∫Ü4‰∏™ËäÇÁÇπÔºàËäÇÁÇπ8ÔºåÂïÜÂä°‰∏≠ÂøÉÔºåÂ£πÂè∑Â§©Á¶ßÔºåËäÇÁÇπ10Ôºâ- **‰∏çÁ¨¶ÂêàËßÑÂàô**\n",
            "* ËäÇÁÇπ10ËøûÊé•‰∫Ü4‰∏™ËäÇÁÇπÔºàËäÇÁÇπ9ÔºåÂÖâÊòéÂ∫úÔºåÂåóÈÉ°ÔºåÁªøÂàõÂ§ßÂé¶Ôºâ- **‰∏çÁ¨¶ÂêàËßÑÂàô**\n",
            "\n",
            "‰∏∫‰∫ÜÊª°Ë∂≥ËßÑÂàô3ÔºåÊàë‰ª¨ÈúÄË¶ÅË∞ÉÊï¥ÊãìÊâëÁªìÊûÑÔºåÂáèÂ∞ëËäÇÁÇπ9ÂíåËäÇÁÇπ10ÁöÑËøûÊé•Êï∞„ÄÇ‰∏Ä‰∏™ÊîπËøõÊñπÊ°àÂ¶Ç‰∏ãÔºö\n",
            "\n",
            "```\n",
            "[\n",
            "(1, 8),  # ÁÉ≠Ê∫ê -> ËäÇÁÇπ8\n",
            "(8, 2),  # ËäÇÁÇπ8 -> ÊÄªÈÉ®Âü∫Âú∞\n",
            "(8, 11), # ËäÇÁÇπ8 -> ËäÇÁÇπ11\n",
            "(11, 3), # ËäÇÁÇπ11 -> ÂïÜÂä°‰∏≠ÂøÉ\n",
            "(11, 9), # ËäÇÁÇπ11 -> ËäÇÁÇπ9\n",
            "(9, 7),  # ËäÇÁÇπ9 -> Â£πÂè∑Â§©Á¶ß\n",
            "(9, 10), # ËäÇÁÇπ9 -> ËäÇÁÇπ10\n",
            "(10, 6), # ËäÇÁÇπ10 -> ÂÖâÊòéÂ∫ú\n",
            "(10, 12),# ËäÇÁÇπ10 -> ËäÇÁÇπ12\n",
            "(12, 5), # ËäÇÁÇπ12 -> ÂåóÈÉ°\n",
            "(12, 4)  # ËäÇÁÇπ12 -> ÁªøÂàõÂ§ßÂé¶\n",
            "]\n",
            "```\n",
            "\n",
            "Âú®Ëøô‰∏™ÊîπËøõÊñπÊ°à‰∏≠Ôºö\n",
            "\n",
            "* ËäÇÁÇπ8ËøûÊé•3‰∏™ËäÇÁÇπ (ÁÉ≠Ê∫ê, ÊÄªÈÉ®Âü∫Âú∞, ËäÇÁÇπ11) - Á¨¶ÂêàËßÑÂàô\n",
            "* ËäÇÁÇπ11ËøûÊé•3‰∏™ËäÇÁÇπ (ËäÇÁÇπ8, ÂïÜÂä°‰∏≠ÂøÉ, ËäÇÁÇπ9) - Á¨¶ÂêàËßÑÂàô\n",
            "* ËäÇÁÇπ9ËøûÊé•3‰∏™ËäÇÁÇπ (ËäÇÁÇπ11, Â£πÂè∑Â§©Á¶ß, ËäÇÁÇπ10) - Á¨¶ÂêàËßÑÂàô\n",
            "* ËäÇÁÇπ10ËøûÊé•3‰∏™ËäÇÁÇπ (ËäÇÁÇπ9, ÂÖâÊòéÂ∫ú, ËäÇÁÇπ12) - Á¨¶ÂêàËßÑÂàô\n",
            "* ËäÇÁÇπ12ËøûÊé•3‰∏™ËäÇÁÇπ (ËäÇÁÇπ10, ÂåóÈÉ°, ÁªøÂàõÂ§ßÂé¶) - Á¨¶ÂêàËßÑÂàô\n",
            "\n",
            "ÊâÄÊúâÊñ∞Â¢ûËäÇÁÇπÈÉΩËøûÊé•‰∫Ü3‰∏™ÂÖ∂‰ªñËäÇÁÇπÔºåÁ¨¶ÂêàÊâÄÊúâËßÑÂàô„ÄÇÂõ†Ê≠§Ôºåmark = 1\n",
            "\n",
            "\n",
            "ÊúÄÁªàÁ≠îÊ°àÔºö\n",
            "\n",
            "```\n",
            "[\n",
            "(1, 8),  # ÁÉ≠Ê∫ê -> ËäÇÁÇπ8\n",
            "(8, 2),  # ËäÇÁÇπ8 -> ÊÄªÈÉ®Âü∫Âú∞\n",
            "(8, 11), # ËäÇÁÇπ8 -> ËäÇÁÇπ11\n",
            "(11, 3), # ËäÇÁÇπ11 -> ÂïÜÂä°‰∏≠ÂøÉ\n",
            "(11, 9), # ËäÇÁÇπ11 -> ËäÇÁÇπ9\n",
            "(9, 7),  # ËäÇÁÇπ9 -> Â£πÂè∑Â§©Á¶ß\n",
            "(9, 10), # ËäÇÁÇπ9 -> ËäÇÁÇπ10\n",
            "(10, 6), # ËäÇÁÇπ10 -> ÂÖâÊòéÂ∫ú\n",
            "(10, 12),# ËäÇÁÇπ10 -> ËäÇÁÇπ12\n",
            "(12, 5), # ËäÇÁÇπ12 -> ÂåóÈÉ°\n",
            "(12, 4)  # ËäÇÁÇπ12 -> ÁªøÂàõÂ§ßÂé¶\n",
            "]\n",
            "\n",
            "mark = 1\n",
            "```\n",
            "\n",
            "You haven't provided the input topology. Please provide the list of connections (source_node, destination_node) so I can evaluate it against the rules and provide feedback/corrections.  I need the topology you want me to check.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 608.63ms\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TooManyRequests",
          "evalue": "429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-875ac11551e8>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   )\n\u001b[0;32m---> 27\u001b[0;31m   \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"INSERT_INPUT_HERE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   model_results = {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36msend_message\u001b[0;34m(self, content, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    576\u001b[0m             )\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         response = self.model.generate_content(\n\u001b[0m\u001b[1;32m    579\u001b[0m             \u001b[0mcontents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    831\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;31m# subclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mcore_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;31m# Return the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTooManyRequests\u001b[0m: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "noELMecqa2hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kWIuwKG2_oWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08240b9b-8051-47c3-89a8-1717b5913959"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "Uploading: /gdrive/.shortcut-targets-by-id/1veAOqNEKzwAdn07ZfprTlEQpRJDizSmC/2.jpg\n",
            "[\n",
            "    {\n",
            "        \"role\": \"user\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"file_data\": {\n",
            "                    \"mime_type\": \"application/octet-stream\",\n",
            "                    \"file_uri\": \"https://generativelanguage.googleapis.com/v1beta/files/n9dvci9kknis\"\n",
            "                }\n",
            "            },\n",
            "            {\n",
            "                \"text\": \"\\u8be5\\u56fe\\u662f\\u4e00\\u4e2a\\u9700\\u8981\\u8fdb\\u884c\\u533a\\u57df\\u4f9b\\u70ed\\u7cfb\\u7edf\\u89c4\\u5212\\u8bbe\\u8ba1\\u7684\\u5bf9\\u8c61\\uff0c\\u73b0\\u6709\\u70ed\\u6e90\\u548c\\u516d\\u4e2a\\u8d1f\\u8377\\uff0c\\u9700\\u8981\\u4f60\\u8fdb\\u884c\\u8d1f\\u8d23\\u8bbe\\u8ba1\\u4e00\\u4e2a\\u4f9b\\u70ed\\u7cfb\\u7edf\\u62d3\\u6251\\u7ed3\\u6784\\u3002\\u4f60\\u9700\\u8981\\u5bf9\\u5404\\u4e2a\\u5bf9\\u8c61\\u548c\\u7ba1\\u9053\\u4ea4\\u63a5\\u5904\\u8bbe\\u7f6e\\u8282\\u70b9\\uff0c\\u8282\\u70b9\\u8fde\\u63a5\\u4ee3\\u8868\\u7ba1\\u9053\\uff0c\\u8fd9\\u4e9b\\u7ba1\\u9053\\u4e0d\\u80fd\\u7a7f\\u8fc7\\u5efa\\u7b51\\u53ea\\u5728\\u56fe\\u4e2d\\u7684\\u9053\\u8def\\u8fdb\\u884c\\u8bbe\\u8ba1\\u3002\\\\n\\u5982\\u679c\\u540c\\u5411\\u6709\\u591a\\u4e2a\\u8d1f\\u8377\\uff0c\\u90a3\\u4e48\\u8be5\\u4e3b\\u7ba1\\u9053\\u9700\\u8981\\u8fdb\\u884c\\u5206\\u652f\\uff0c\\u5e76\\u4e14\\u5206\\u652f\\u540e\\u7684\\u65b0\\u8282\\u70b9\\u8fde\\u63a5\\u81f3\\u8fd9\\u4e24\\u4e2a\\u8d1f\\u8377\\u3002\\\\n\\u540c\\u4e00\\u4e2a\\u8282\\u70b9\\u4e0d\\u80fd\\u8fde\\u63a5\\u8d85\\u8fc73\\u4e2a\\u7ba1\\u9053\\uff0c\\u5982\\u679c\\u6709\\u9700\\u8981\\u8bbe\\u8ba1\\u7ba1\\u9053\\u5206\\u652f\\u3002\\\\n\\\\n\\u53c2\\u8003\\uff1a\\u70ed\\u6e90\\u8282\\u70b9\\u7f16\\u53f7\\u4e3a1\\uff1b\\u603b\\u90e8\\u57fa\\u5730\\u8282\\u70b9\\u7f16\\u53f7\\u4e3a2\\uff1b\\u5546\\u52a1\\u4e2d\\u5fc3\\u8282\\u70b9\\u7f16\\u53f7\\u4e3a3\\uff1b\\u7eff\\u521b\\u5927\\u53a6\\u8282\\u70b9\\u7f16\\u53f7\\u4e3a4\\uff1b\\u5317\\u90e1\\u8282\\u70b9\\u7f16\\u53f7\\u4e3a5\\uff1b\\u5149\\u660e\\u5e9c\\u8282\\u70b9\\u7f16\\u53f7\\u4e3a6\\uff1b\\u58f9\\u53f7\\u5929\\u79a7\\u8282\\u70b9\\u7f16\\u53f7\\u4e3a7\\u3002\\u4f60\\u8fd8\\u9700\\u8981\\u5bf9\\u5176\\u4ed6\\u8282\\u70b9\\u989d\\u5916\\u5b9a\\u4e49\\u7f16\\u53f7\\u3002\\\\n\\\\n\\u8bf7\\u4f60\\u7528\\u8fd4\\u56de\\u4e00\\u4e2a\\u5217\\u8868\\uff0c\\u5176\\u4e2d\\u5217\\u8868\\u5143\\u7d20\\u5305\\u542b\\uff08node_id1,node_id2\\uff09\\u4ee3\\u8868\\u4ece\\u8282\\u70b9\\u7f16\\u53f7node_id1\\u6d41\\u5165\\u8282\\u70b9\\u7f16\\u53f7node_id2\\u3002\\\\n\\u7ed3\\u679c\\u6a21\\u7248\\u4f8b\\u5982\\uff1a\\u201c[\\\\n(1, 5), # \\u70ed\\u6e90 -> \\u8282\\u70b95\\\\n(5, 6), # \\u8282\\u70b95 -> \\u8282\\u70b96\\\\n(6, 2), # \\u8282\\u70b96 -> \\u603b\\u90e8\\u57fa\\u5730\\\\n(6, 4), # \\u8282\\u70b96 -> \\u58f9\\u53f7\\u5929\\u79a7\\\\n(5, 3) # \\u8282\\u70b95 -> \\u5546\\u52a1\\u4e2d\\u5fc3\\\\n]\\u201d\"\n",
            "            }\n",
            "        ]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"model\",\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"```\\\\n[\\\\n(1, 8),  # \\u70ed\\u6e90 -> \\u8282\\u70b98\\\\n(8, 9),  # \\u8282\\u70b98 -> \\u8282\\u70b99\\\\n(9, 7),  # \\u8282\\u70b99 -> \\u58f9\\u53f7\\u5929\\u79a7\\\\n(9, 2),  # \\u8282\\u70b99 -> \\u603b\\u90e8\\u57fa\\u5730\\\\n(8, 10), # \\u8282\\u70b98 -> \\u8282\\u70b910\\\\n(10, 11),# \\u8282\\u70b910 -> \\u8282\\u70b911\\\\n(11, 4), # \\u8282\\u70b911 -> \\u7eff\\u521b\\u5927\\u53a6\\\\n(11, 3), # \\u8282\\u70b911 -> \\u5546\\u52a1\\u4e2d\\u5fc3\\\\n(10, 12),# \\u8282\\u70b910 -> \\u8282\\u70b912\\\\n(12, 5), # \\u8282\\u70b912 -> \\u5317\\u90e1\\\\n(12, 6), # \\u8282\\u70b912 -> \\u5149\\u660e\\u5e9c\\\\n]\\\\n```\"\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# import necessary modules.\n",
        "import base64\n",
        "import copy\n",
        "import json\n",
        "import pathlib\n",
        "import requests\n",
        "\n",
        "\n",
        "import PIL.Image\n",
        "import IPython.display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "try:\n",
        "    # The SDK will automatically read it from the GOOGLE_API_KEY environment variable.\n",
        "    # In Colab get the key from Colab-secrets (\"üîë\" in the left panel).\n",
        "    import os\n",
        "    from google.colab import userdata\n",
        "\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Parse the arguments\n",
        "\n",
        "model = 'gemini-1.5-pro' # @param {isTemplate: true}\n",
        "contents_b64 = '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' # @param {isTemplate: true}\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MCwidG9wX3AiOjAuOTUsInRvcF9rIjo0MCwibWF4X291dHB1dF90b2tlbnMiOjgxOTJ9' # @param {isTemplate: true}\n",
        "safety_settings_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "\n",
        "gais_contents = json.loads(base64.b64decode(contents_b64))\n",
        "\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "\n",
        "stream = False\n",
        "\n",
        "# Convert and upload the files\n",
        "\n",
        "tempfiles = pathlib.Path(f\"tempfiles\")\n",
        "tempfiles.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "drive = None\n",
        "def upload_file_data(file_data, index):\n",
        "    \"\"\"Upload files to the Files API.\n",
        "\n",
        "    For each file, Google AI Studio either sent:\n",
        "    - a Google Drive ID,\n",
        "    - a URL,\n",
        "    - a file path, or\n",
        "    - The raw bytes (`inline_data`).\n",
        "\n",
        "    The API only understands `inline_data` or it's Files API.\n",
        "    This code, uploads files to the files API where the API can access them.\n",
        "    \"\"\"\n",
        "\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "    if drive_id := file_data.pop(\"drive_id\", None):\n",
        "\n",
        "        # if drive is None:\n",
        "        from google.colab import drive\n",
        "        drive.mount(\"/gdrive\")\n",
        "\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        print(\"Uploading:\", str(path))\n",
        "        file_info = genai.upload_file(path=path, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if url := file_data.pop(\"url\", None):\n",
        "        response = requests.get(url)\n",
        "        data = response.content\n",
        "        name = url.split(\"/\")[-1]\n",
        "        path = tempfiles / str(index)\n",
        "        path.write_bytes(data)\n",
        "        print(\"Uploading:\", url)\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files \"\n",
        "                'to Colab using the file manager (\"üìÅ Files\" in the left '\n",
        "                \"toolbar)\"\n",
        "            )\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if \"inline_data\" in file_data:\n",
        "        return\n",
        "\n",
        "    raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")\n",
        "\n",
        "\n",
        "contents = copy.deepcopy(gais_contents)\n",
        "\n",
        "index = 0\n",
        "for content in contents:\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if file_data := part.get(\"file_data\", None):\n",
        "            upload_file_data(file_data, index)\n",
        "            index += 1\n",
        "\n",
        "import json\n",
        "print(json.dumps(contents, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zAD69vE92b"
      },
      "source": [
        "## Call `generate_content`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LB2LxPmAB95V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "76e620e4-adb9-4464-aa51-f665a2d628c9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgument",
          "evalue": "400 Unable to submit request because it has a mimeType parameter with value application/octet-stream, which is not supported. Update the mimeType and try again. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9d959b37a0ec>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgemini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerativeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m response = gemini.generate_content(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    831\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgument\u001b[0m: 400 Unable to submit request because it has a mimeType parameter with value application/octet-stream, which is not supported. Update the mimeType and try again. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini"
          ]
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "response = gemini.generate_content(\n",
        "    contents,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        "    stream=stream\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9d345e9868"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemini-api/docs\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />Docs on ai.google.dev</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google-gemini/cookbook/blob/main/quickstarts\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />More notebooks in the Cookbook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F91AeeGO1ncU"
      },
      "source": [
        "## [optional] Show the conversation\n",
        "\n",
        "This section displays the conversation received from Google AI Studio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoL3p3KPylFW"
      },
      "outputs": [],
      "source": [
        "# @title Show the conversation, in colab.\n",
        "import mimetypes\n",
        "\n",
        "def show_file(file_data):\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "\n",
        "    if drive_id := file_data.get(\"drive_id\", None):\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        name = path\n",
        "        # data = path.read_bytes()\n",
        "        kwargs = {\"filename\": path}\n",
        "    elif url := file_data.get(\"url\", None):\n",
        "        name = url\n",
        "        kwargs = {\"url\": url}\n",
        "        # response = requests.get(url)\n",
        "        # data = response.content\n",
        "    elif data := file_data.get(\"inline_data\", None):\n",
        "        name = None\n",
        "        kwargs = {\"data\": data}\n",
        "    elif name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files to \"\n",
        "                'Colab using the file manager (\"üìÅ Files\"in the left toolbar)'\n",
        "            )\n",
        "    else:\n",
        "        raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")\n",
        "\n",
        "        print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")\n",
        "        return\n",
        "\n",
        "    format = mimetypes.guess_extension(mime_type).strip(\".\")\n",
        "    if mime_type.startswith(\"image/\"):\n",
        "        image = IPython.display.Image(**kwargs, width=256)\n",
        "        IPython.display.display(image)\n",
        "        print()\n",
        "        return\n",
        "\n",
        "    if mime_type.startswith(\"audio/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Audio(**kwargs)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    if mime_type.startswith(\"video/\"):\n",
        "        if len(data) < 2**12:\n",
        "            audio = IPython.display.Video(**kwargs, mimetype=mime_type)\n",
        "            IPython.display.display(audio)\n",
        "            print()\n",
        "            return\n",
        "\n",
        "    print(f\"File:\\n    name: {name}\\n    mime_type: {mime_type}\\n\")\n",
        "\n",
        "\n",
        "for content in gais_contents:\n",
        "    if role := content.get(\"role\", None):\n",
        "        print(\"Role:\", role, \"\\n\")\n",
        "\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if text := part.get(\"text\", None):\n",
        "            print(text, \"\\n\")\n",
        "\n",
        "        elif file_data := part.get(\"file_data\", None):\n",
        "            show_file(file_data)\n",
        "\n",
        "    print(\"-\" * 80, \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "aistudio_gemini_prompt_freeform.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}